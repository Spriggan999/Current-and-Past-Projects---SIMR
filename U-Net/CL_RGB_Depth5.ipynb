{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "1DLPfo6CG_gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zY1x-lzW4H3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUwaCKuZ1f9a"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "#Load data for U-net training\n",
        "import os\n",
        "\n",
        "#Color Channel Experimentation\n",
        "import skimage\n",
        "import skimage.color as scc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIXlA0kR3m1r"
      },
      "outputs": [],
      "source": [
        "#SIZE = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr6FX4BQjQ77"
      },
      "outputs": [],
      "source": [
        "#Image_Dataset: MRI/Anatomical Images - Greyscale\n",
        "MRI_dataset = []\n",
        "image_directory = os.listdir(\"/content/drive/MyDrive/VCU_Lab/TBI_Sorted/Anatomical/\")\n",
        "image_directory = sorted(image_directory)\n",
        "print(image_directory)\n",
        "\n",
        "for i in range(len(image_directory)):\n",
        "  img = cv2.imread(\"/content/drive/MyDrive/VCU_Lab/TBI_Sorted/Anatomical/\"+image_directory[i])\n",
        "  print(image_directory[i])\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
        "  MRI_dataset.append(img_to_array(img))\n",
        "\n",
        "MRI_dataset = np.asarray(MRI_dataset)\n",
        "print(MRI_dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4XYCAzZDioH"
      },
      "outputs": [],
      "source": [
        "#Label Data Pre-processing\n",
        "#Image_Dataset: E-field Images - RGB\n",
        "mask_directory = os.listdir('/content/drive/MyDrive/VCU_Lab/TBI_Sorted/E_Field/')\n",
        "mask_directory = sorted(mask_directory)\n",
        "Efield_dataset_raw = []\n",
        "\n",
        "for i in range(len(mask_directory)):\n",
        "\n",
        "\n",
        "  img = cv2.imread(\"/content/drive/MyDrive/VCU_Lab/TBI_Sorted/E_Field/\"+mask_directory[i])\n",
        "  print(mask_directory[i])\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  Efield_dataset_raw.append(img_to_array(img))\n",
        "\n",
        "\n",
        "Efield_dataset_raw = np.asarray(Efield_dataset_raw)\n",
        "print(Efield_dataset_raw.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7XU2E4ljelN"
      },
      "outputs": [],
      "source": [
        "#Data Normalization \n",
        "# MRI Normalization remains the same for all three sets of anatomical images\n",
        "max_image = np.max(MRI_dataset)\n",
        "min_image = np.min(MRI_dataset)\n",
        "MRI_dataset = (MRI_dataset - min_image)/(max_image - min_image)\n",
        "\n",
        "# E Field Normalization for RGB E-Field Images\n",
        "max_mask = np.max(Efield_dataset_raw)\n",
        "min_mask = np.min(Efield_dataset_raw)\n",
        "Efield_dataset = (Efield_dataset_raw - min_mask)/(max_mask - min_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF5pO_Iyjmeq"
      },
      "outputs": [],
      "source": [
        "# Dataset Split\n",
        "train_data, validation_data, train_mask, validation_mask  = train_test_split(MRI_dataset, Efield_dataset, test_size=0.1, random_state=1, shuffle=True)\n",
        "print(train_data.shape)\n",
        "print(validation_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHZO8AzwjwC1"
      },
      "outputs": [],
      "source": [
        "#Sanity check of image-mask set\n",
        "image_number = np.random.randint(0, len(train_data))\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.squeeze(train_data[image_number]), cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.squeeze(train_mask[image_number]), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ithJq47anGXP"
      },
      "outputs": [],
      "source": [
        "# Training Parameters\n",
        "Epoch = 200 \n",
        "batch_size = 1 \n",
        "\n",
        "input_shape = (1024, 1024, 1)\n",
        "inputs = Input(shape = input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i6D6C9kj4Iw"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate\n",
        "\n",
        "#Convolutional block to be used in U-Net\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, (3,3), padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)    \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, (3,3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)  \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#Encoder block for U-net: Conv block followed by maxpooling\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p   \n",
        "\n",
        "#Decoder block for U-net\n",
        "#skip features gets input from encoder for concatenation\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(2*num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "#Build Unet using the blocks\n",
        "def build_unet_depthfive(inputs):\n",
        "    s1, p1 = encoder_block(inputs, 8)\n",
        "    s2, p2 = encoder_block(p1, 16)\n",
        "    s3, p3 = encoder_block(p2, 32)\n",
        "    s4, p4 = encoder_block(p3, 64)\n",
        "    s5, p5 = encoder_block(p4, 128)\n",
        "\n",
        "    b1 = conv_block(p5, 256) #Bridge\n",
        "\n",
        "    d1 = decoder_block(b1, s5, 128)\n",
        "    d2 = decoder_block(d1, s4, 64)\n",
        "    d3 = decoder_block(d2, s3, 32)\n",
        "    d4 = decoder_block(d3, s2, 16)\n",
        "    d5 = decoder_block(d4, s1, 8)\n",
        "\n",
        "    outputs = Conv2D(3, (3,3), padding=\"same\", activation=\"sigmoid\")(d5)  #Binary (can be multiclass)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "Unet = Model(inputs, build_unet_depthfour(inputs))\n",
        "Unet.compile(loss='mse', optimizer = Adam())\n",
        "print(Unet.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0CYJSAMwGWp"
      },
      "outputs": [],
      "source": [
        " #Train the model\n",
        "\n",
        "Unet_model_history = Unet.fit(train_data, train_mask, \n",
        "                    verbose=1,\n",
        "                    batch_size = batch_size,\n",
        "                    validation_data=(validation_data, validation_mask), \n",
        "                    epochs=Epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6Gv32LJx4Lo"
      },
      "outputs": [],
      "source": [
        "#Plot the training and validation loss at each epoch\n",
        "print(Unet_model_history.history)\n",
        "loss = Unet_model_history.history['loss']\n",
        "val_loss = Unet_model_history.history['val_loss']\n",
        "epochs = range(Epoch)\n",
        "plt.figure(figsize=(40, 20))\n",
        "plt.plot(epochs, loss, 'g', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the training and validation loss at each epoch\n",
        "print(Unet_model_history.history)\n",
        "loss = Unet_model_history.history['loss']\n",
        "\n",
        "epochs = range(Epoch)\n",
        "plt.figure(figsize=(40, 20))\n",
        "plt.plot(epochs, loss, 'g', label='Training loss')\n",
        "\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BHBqnqBOvlEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the training and validation loss at each epoch\n",
        "print(Unet_model_history.history)\n",
        "\n",
        "val_loss = Unet_model_history.history['val_loss']\n",
        "epochs = range(Epoch)\n",
        "plt.figure(figsize=(40, 20))\n",
        "\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9IYSp8f3vqfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdQiAn8hySdr"
      },
      "outputs": [],
      "source": [
        "#Test the model\n",
        "\n",
        "Unet_model_test = Unet.evaluate(validation_data, validation_mask, \n",
        "                                batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unet.save('Unet_12_24_22.h5')"
      ],
      "metadata": {
        "id": "8sGKalVntH0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_train = Unet.predict(train_data)\n",
        "predict_val = Unet.predict(validation_data)"
      ],
      "metadata": {
        "id": "swE90WKGMhzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPkAPiM5zpTK"
      },
      "outputs": [],
      "source": [
        "mse_train = np.mean((train_mask - predict_train) ** 2)\n",
        "psnr_train = 10 * math.log10( 1 / mse_train)\n",
        "print('MSE-Training:', mse_train)\n",
        "print('Training Data PSNR: {psnr_train}dB'.format(psnr_train=np.round(psnr_train,2)))\n",
        "\n",
        "mse_val = np.mean((validation_mask - predict_val) ** 2)\n",
        "psnr_val = 10 * math.log10( 1 / mse_val)\n",
        "print('MSE-Validation:', mse_val)\n",
        "print('Validation Data PSNR: {psnr_val}dB'.format(psnr_val=np.round(psnr_val,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wHuqOkrz0O8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "print(\"Ground Truth:\")\n",
        "for i in range(5):\n",
        "  plt.subplot(1, 5, i+1)\n",
        "  plt.imshow(train_mask[i])\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "print(\"Prediction:\")\n",
        "for i in range(5):\n",
        "  plt.subplot(1, 5, i+1)\n",
        "  plt.imshow(predict_train[i])\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "print(\"Ground Truth:\")\n",
        "for i in range(5):\n",
        "  plt.subplot(1, 5, i+1)\n",
        "  plt.imshow(train_mask[i+5])\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "print(\"Prediction:\")\n",
        "for i in range(5):\n",
        "  plt.subplot(1, 5, i+1)\n",
        "  plt.imshow(predict_train[i+5])\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "print(\"Ground Truth:\")\n",
        "for i in range(5):\n",
        "  plt.subplot(1, 5, i+1)\n",
        "  plt.imshow(train_mask[i+10])\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "print(\"Prediction:\")\n",
        "for i in range(5):\n",
        "  plt.subplot(1, 5, i+1)\n",
        "  plt.imshow(predict_train[i+10])\n",
        "plt.show()\n",
        "\n",
        "#plt.figure(figsize=(20, 10))\n",
        "#print(\"Ground Truth:\")\n",
        "#for i in range(3):\n",
        "#  plt.subplot(1, 3, i+1)\n",
        "# plt.imshow(validation_mask[i])\n",
        "#plt.show()\n",
        "\n",
        "#plt.figure(figsize=(20, 10))\n",
        "#print(\"Prediction:\")\n",
        "#for i in range(3):\n",
        "#  plt.subplot(1, 3, i+1)\n",
        "#  plt.imshow(predict_val[i])\n",
        "#plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "print(\"Ground Truth:\")\n",
        "for i in range(7):\n",
        "  plt.subplot(1, 7, i+1)\n",
        "  plt.imshow(validation_mask[i])\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "print(\"Prediction:\")\n",
        "for i in range(7):\n",
        "  plt.subplot(1, 7, i+1)\n",
        "  plt.imshow(predict_val[i])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOYMS5smZ_AY"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "Epochs = list(range(1, 201))\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=Epochs, y=loss,\n",
        "                    mode='lines+markers',\n",
        "                    name='Training Loss'))\n",
        "fig.add_trace(go.Scatter(x=Epochs, y=val_loss,\n",
        "                    mode='lines+markers',\n",
        "                    name='Validation Loss'))\n",
        "fig.update_xaxes(title_text=\"Epochs\")\n",
        "fig.update_yaxes(title_text=\"Loss (MSE)\")\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}